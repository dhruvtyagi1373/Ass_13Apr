{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54ec2593-e658-4b14-958a-412bde5693f7",
   "metadata": {},
   "source": [
    "## Q1. What is Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a19515f-3991-4fba-90a1-c9373481a200",
   "metadata": {},
   "source": [
    "Sol : Random forest regression is a supervised learning algorithm and bagging technique that uses an ensemble learning method for regression in machine learning. The trees in random forests run in parallel, meaning there is no interaction between these trees while building the trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c551601-b91d-441e-bd13-2064a4a3d050",
   "metadata": {},
   "source": [
    "## Q2. How does Random Forest Regressor reduce the risk of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1fe141-b125-4c6f-b91f-06510b043a72",
   "metadata": {},
   "source": [
    "Sol :  In general, random forests are much less likely to overfit than other models because they are made up of many weak classifiers that are trained completely independently on completely different subsets of the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad4097-7b9e-4e61-86b2-4db580a8a082",
   "metadata": {},
   "source": [
    "## Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b448cf79-158e-403a-b9ba-dcfba1e7bad1",
   "metadata": {},
   "source": [
    "Sol : It leverages an ensemble of multiple decision trees to generate predictions or classifications. By combining the outputs of these trees, the random forest regressor algorithm delivers a consolidated and more accurate result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bb9aa8-9527-4fbc-8e0d-d346892c32fb",
   "metadata": {},
   "source": [
    "## Q4. What are the hyperparameters of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bec0ff-8763-4ffd-af2b-5f7fe35beb18",
   "metadata": {},
   "source": [
    "Sol : n_estimators=100, *, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3795df5-1cbf-4de6-bff2-815961a9fbbe",
   "metadata": {},
   "source": [
    "## Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f372b-9d7f-430e-8b7c-6b64608585da",
   "metadata": {},
   "source": [
    "Sol : In Random Forest Regressor it ensemble various Decision Tree Regressor models each trained with a sample of data and combines the output of these trees, while in Decision Tree Regressor a single Decision Tree is used to predict the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8120d8e0-7d94-4904-a559-ff43c9fe1e8f",
   "metadata": {},
   "source": [
    "## Q6. What are the advantages and disadvantages of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f0953e-56ee-4bb6-abf5-b88746662a0e",
   "metadata": {},
   "source": [
    "Advantages-\n",
    "- It reduces overfitting in decision trees and helps to improve the accuracy.\n",
    "- It automates missing values present in the data\n",
    "- Normalising of data is not required as it uses a rule-based approach.\n",
    "\n",
    "Disadvantages-\n",
    "- It requires much computational power as well as resources as it builds numerous trees to combine their outputs. \n",
    "- It also requires much time for training as it combines a lot of decision trees to determine the class.\n",
    "- Due to the ensemble of decision trees, it also suffers interpretability and fails to determine the significance of each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75b7a89-9272-4091-ae8b-16e9f961cbb8",
   "metadata": {},
   "source": [
    "## Q7. What is the output of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca00167-4524-413f-b752-c9a812c2841d",
   "metadata": {},
   "source": [
    "Sol : Random Forest Regressor gives average of all the outputs given by different Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b1881a-37b6-4f4b-95c6-6a43ac57f848",
   "metadata": {},
   "source": [
    "## Q8. Can Random Forest Regressor be used for classification tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1510303a-6bdd-48e2-bdf8-0268c881cd18",
   "metadata": {},
   "source": [
    "Sol : No because we use Decision Tree Regressor in Random Forest Regressor that will require continous values for dependent variable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
